python -W ignore train_vae.py \
    --htr_path "pretrained_models/emuru_vae_htr" \
    --writer_id_path "pretrained_models/emuru_vae_writer_id" \
    --train_batch_size 128 \
    --epochs 4 \
    --lr 5e-5 \
    --mixed_precision fp16 \
    --keep_background True \
    --report_to "wandb" \
    --wandb_entity "ruian7p" \
    --wandb_project_name "emuru_vae" \
    --wandb_log_interval_steps 100